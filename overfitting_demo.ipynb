{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "# from demo import BATCH_SIZE, DEVICE, EPOCHS, LEARNING_RATE, NUM_WORKERS, RUN_FOLDER, WEIGHT_DECAY\n",
    "from net import resnet50\n",
    "from utils import ISIC2018Dataset, save_model, Logger, Evaluation, plot_confusion_matrix, plot_roc_curves, plot_losses\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER = './demo'\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "EPOCHS = 100\n",
    "LEARNING_RATE = 0.0005\n",
    "WEIGHT_DECAY  = 0.2\n",
    "\n",
    "if not os.path.exists(RUN_FOLDER):\n",
    "    os.makedirs(RUN_FOLDER)\n",
    "    os.makedirs(os.path.join(RUN_FOLDER,'images'))\n",
    "    os.makedirs(os.path.join(RUN_FOLDER,'models'))\n",
    "\n",
    "LOGGER = Logger(RUN_FOLDER,'demo')\n",
    "LOGGER.info('isic2018 demo run by cc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_trans1 = transforms.Compose([\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "train_trans2 = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "\n",
    "train_trans3 = transforms.Compose([\n",
    "    transforms.ColorJitter(contrast=0.5),\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
    "                         std=[0.229,0.224,0.225])\n",
    "])\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_trans = [train_trans1,train_trans2,train_trans3]\n",
    "train_dataset = []\n",
    "for train in train_trans:\n",
    "    train_dataset.append(ISIC2018Dataset(\n",
    "    csv_file_path='./data/ISIC2018/Train_GroundTruth.csv',\n",
    "    img_dir='./data/ISIC2018/ISIC2018_Task3_Training_Input',\n",
    "    transform=train))\n",
    "\n",
    "test_dataset = ISIC2018Dataset(\n",
    "    csv_file_path='./data/ISIC2018/Test_GroundTruth.csv',\n",
    "    img_dir='./data/ISIC2018/ISIC2018_Task3_Training_Input',\n",
    "    transform=test_trans\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = []\n",
    "for data in train_dataset:\n",
    "    train_iter.append(\n",
    "            DataLoader( data,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        drop_last=True,\n",
    "                        num_workers=NUM_WORKERS))\n",
    "                        \n",
    "test_iter = DataLoader(test_dataset,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = resnet50(num_classes = 7)\n",
    "net = net.to(DEVICE)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='sum')\n",
    "optim = torch.optim.Adam(net.parameters(),\n",
    "                        lr=LEARNING_RATE,\n",
    "                        weight_decay=WEIGHT_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_iter,test_iter=test_iter,net=net,loss_fn=loss_fn,version = ''):\n",
    "    train_l = []\n",
    "    train_acc = []\n",
    "    test_l = []\n",
    "    test_acc = []\n",
    "    for epoch in range(EPOCHS):\n",
    "        correct = 0\n",
    "        num_data = 0\n",
    "        losses = 0\n",
    "        net.train()\n",
    "        for X,y in train_iter:\n",
    "            num_data += X.shape[0]\n",
    "            X,y = X.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "            out = net(X)\n",
    "            l = loss_fn(out,y)\n",
    "\n",
    "            l.backward()\n",
    "            optim.step()\n",
    "\n",
    "            losses += l.cpu().detach().item()\n",
    "            yhat = out.argmax(dim=1)\n",
    "            correct += (yhat == y).sum().cpu().detach().item()\n",
    "\n",
    "        loss = losses / num_data\n",
    "        acc = correct / num_data\n",
    "        train_l.append(loss)\n",
    "        train_acc.append(acc)\n",
    "\n",
    "        correct,num_data,losses = 0,0,0\n",
    "        net.eval()\n",
    "        for X, y in test_iter:\n",
    "            num_data += X.shape[0]\n",
    "            X, y = X.to(DEVICE), y.to(DEVICE)\n",
    "            with torch.no_grad():\n",
    "                out = net(X)\n",
    "                l = loss_fn(out, y)\n",
    "\n",
    "                losses += l.cpu().detach().item()\n",
    "                yhat = out.argmax(dim=1)\n",
    "                correct += (yhat == y).sum().cpu().detach().item()\n",
    "\n",
    "        loss = losses / num_data\n",
    "        acc = correct / num_data\n",
    "        test_l.append(loss)\n",
    "        test_acc.append(acc)\n",
    "\n",
    "        LOGGER.info(\"Epoch {:03d} --- train loss: {:.4f} train acc: {:.4f}\\ttest loss: {:.4f} test acc: {:.4f}\".format(\n",
    "        epoch+1, train_l[-1], train_acc[-1], test_l[-1], test_acc[-1]))\n",
    "\n",
    "    plot_losses([train_l, train_acc, test_l, test_acc],\n",
    "            title=\"loss and acc\",\n",
    "            legend=[\"train loss\", \"train acc\", \"test loss\", \"test acc\"],\n",
    "            filename=os.path.join(RUN_FOLDER, \"images\", \"loss.png\"+version))\n",
    "\n",
    "    save_model(model=net, path=os.path.join(RUN_FOLDER, \"models\"+version))\n",
    "\n",
    "    # 模型评估\n",
    "    evaluation = Evaluation(net, test_iter, DEVICE,\n",
    "                        categories=test_dataset.categories)\n",
    "    report = evaluation.get_report()\n",
    "    LOGGER.info(report)\n",
    "    result = evaluation.evaluate([\"c_matrix\", \"roc_curves\"])\n",
    "    plot_confusion_matrix(result[\"c_matrix\"], test_dataset.categories,\n",
    "                      title=\"confusion matrix\",\n",
    "                      filename=os.path.join(RUN_FOLDER, \"images\", \"cm{}.png\".format(version)))\n",
    "    plot_roc_curves(result[\"roc_curves\"][0],\n",
    "                result[\"roc_curves\"][1],\n",
    "                result[\"roc_curves\"][2],\n",
    "                categories=test_dataset.categories,\n",
    "                filename=os.path.join(RUN_FOLDER, \"images\", \"roc_curve{}.png\".format(version)))\n",
    "    return train_acc[-1],test_acc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "train_acc,test_acc = [],[]\n",
    "\n",
    "for iter,idx in enumerate(train_iter):\n",
    "    temp = train(iter,version=idx)\n",
    "    train_acc.append(temp[0])\n",
    "    test_acc.append(temp[1])\n",
    "\n",
    "x = [1,2,3]\n",
    "plt.bar(x,train_acc,lw=0.5,fc=\"r\",width=0.3,label=\"train\")\n",
    "plt.bar(x,test_acc,lw=0.5,fc=\"b\",width=0.3,label=\"test\")\n",
    "\n",
    "plt.title(\"实验对照\")\n",
    "plt.xlabel(\"组别\")\n",
    "plt.ylabel(\"准确度\")\n",
    "\n",
    "plt.savefig(os.path.join(RUN_FOLDER, \"images\", \"acc.png\"), dpi=300)\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}