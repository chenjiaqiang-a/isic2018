{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import torch\n",
    "import warnings\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from utils import ISIC2018Dataset, Evaluation, load_model, plot_confusion_matrix, plot_roc_curves, plot_losses, Logger\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据准备\n",
    "我将对各个训练好的模型在训练集、验证集、测试集上进行评估，因而所有的图片都进行以下相同的预处理\n",
    "- 最小边放缩至224\n",
    "- 中心裁剪大小为[224, 224]的区域\n",
    "- 转换成PyTorch使用的tensor形式\n",
    "- 应用正则化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 数据预处理\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "test_trans = transforms.Compose([\n",
    "    transforms.Resize(224),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_dataset = ISIC2018Dataset(\n",
    "    csv_file_path='./data/ISIC2018/Train_GroundTruth.csv',\n",
    "    img_dir='./data/ISIC2018/ISIC2018_Task3_Training_Input',\n",
    "    transform=test_trans\n",
    ")\n",
    "\n",
    "valid_dataset = ISIC2018Dataset(\n",
    "    csv_file_path='./data/ISIC2018/ISIC2018_Task3_Validation_GroundTruth.csv',\n",
    "    img_dir='./data/ISIC2018/ISIC2018_Task3_Validation_Input',\n",
    "    transform=test_trans\n",
    ")\n",
    "\n",
    "test_dataset = ISIC2018Dataset(\n",
    "    csv_file_path='./data/ISIC2018/Test_GroundTruth.csv',\n",
    "    img_dir='./data/ISIC2018/ISIC2018_Task3_Training_Input',\n",
    "    transform=test_trans\n",
    ")\n",
    "\n",
    "train_iter = DataLoader(train_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=NUM_WORKERS)\n",
    "valid_iter = DataLoader(valid_dataset,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=NUM_WORKERS)\n",
    "test_iter = DataLoader(test_dataset,\n",
    "                       batch_size=BATCH_SIZE,\n",
    "                       num_workers=NUM_WORKERS)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 模型评估\n",
    "为了评估ohem算法对类别倾斜的解决效果，我选择了如下评价指标：\n",
    "- accuracy\n",
    "- balanced accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "- confusion matrix\n",
    "- roc curves(roc-auc)\n",
    "\n",
    "同时我还绘制了训练过程中损失和准确率的变化曲线\n",
    "\n",
    "### 对照组评估\n",
    "对照组即不使用任何应对类别倾斜的方法，按照正常的训练流程训练得到的模型。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "RUN_FOLDER = './run/control'\n",
    "LOGGER = Logger(run_folder=RUN_FOLDER, title='test')\n",
    "LOGGER.info(\"Evaluation for control\")\n",
    "RUN_IDS = ['0001', '0002', '0003']\n",
    "\n",
    "evaluation = Evaluation(device=DEVICE, categories=test_dataset.categories)\n",
    "\n",
    "for run_id in RUN_IDS:\n",
    "    loss_acc = pickle.load(open(os.path.join(RUN_FOLDER, run_id+'obj.pkl'), 'rb'))\n",
    "    plot_losses([loss_acc['train_loss'], loss_acc['train_acc'], loss_acc['valid_loss'], loss_acc['valid_acc']],\n",
    "                title=f\"control {run_id} loss and acc\",\n",
    "                legend=[\"train loss\", \"train acc\", \"valid loss\", \"valid acc\"],\n",
    "                filename=os.path.join(RUN_FOLDER, \"images\", f\"control-{run_id}-loss.png\"))\n",
    "\n",
    "    model = load_model(os.path.join(RUN_FOLDER, \"models\", run_id+\"model.pkl\"),\n",
    "                       device=DEVICE)\n",
    "    for dataset, data_loader in zip(['train', 'valid', 'test'], [train_iter, valid_iter, test_iter]):\n",
    "        LOGGER.info(f\"model {run_id} for {dataset} dataset\")\n",
    "        report = evaluation.get_report(model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"\\n{report}\")\n",
    "        result = evaluation.evaluate(metric=['acc', 'b_acc', 'precision', 'recall', 'f1_score', 'c_matrix', 'roc_curves'],\n",
    "                                     model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"acc:       {result['acc']:.4f}\\n\"\n",
    "                    f\"b_acc:     {result['b_acc']:.4f}\\n\"\n",
    "                    f\"precision: {result['precision']}\\n\"\n",
    "                    f\"recall:    {result['recall']}\\n\"\n",
    "                    f\"f1_score:  {result['f1_score']}\")\n",
    "        plot_confusion_matrix(result[\"c_matrix\"], test_dataset.categories,\n",
    "                              title=f\"control {run_id} confusion matrix for {dataset}\",\n",
    "                              filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-cm.png\"))\n",
    "        plot_roc_curves(result[\"roc_curves\"][0],\n",
    "                        result[\"roc_curves\"][1],\n",
    "                        result[\"roc_curves\"][2],\n",
    "                        categories=test_dataset.categories,\n",
    "                        filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-roc_curve.png\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 实验组评估\n",
    "实验组在训练过程中使用了ohem算法，希望能够应对类别倾斜的问题。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER = './run/ohem'\n",
    "LOGGER = Logger(run_folder=RUN_FOLDER, title='test')\n",
    "LOGGER.info(\"Evaluation for ohem\")\n",
    "RUN_IDS = ['0001', '0002', '0003', '0004', '0005', '0006']\n",
    "\n",
    "evaluation = Evaluation(device=DEVICE, categories=test_dataset.categories)\n",
    "\n",
    "for run_id in RUN_IDS:\n",
    "    loss_acc = pickle.load(open(os.path.join(RUN_FOLDER, run_id+'obj.pkl'), 'rb'))\n",
    "    plot_losses([loss_acc['train_loss'], loss_acc['train_acc'], loss_acc['valid_loss'], loss_acc['valid_acc']],\n",
    "                title=f\"ohem {run_id} loss and acc\",\n",
    "                legend=[\"train loss\", \"train acc\", \"valid loss\", \"valid acc\"],\n",
    "                filename=os.path.join(RUN_FOLDER, \"images\", f\"ohem-{run_id}-loss.png\"))\n",
    "\n",
    "    model = load_model(os.path.join(RUN_FOLDER, \"models\", run_id+\"model.pkl\"),\n",
    "                       device=DEVICE)\n",
    "    for dataset, data_loader in zip(['train', 'valid', 'test'], [train_iter, valid_iter, test_iter]):\n",
    "        LOGGER.info(f\"model {run_id} for {dataset} dataset\")\n",
    "        report = evaluation.get_report(model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"\\n{report}\")\n",
    "        result = evaluation.evaluate(metric=['acc', 'b_acc', 'precision', 'recall', 'f1_score', 'c_matrix', 'roc_curves'],\n",
    "                                     model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"acc:       {result['acc']:.4f}\\n\"\n",
    "                    f\"b_acc:     {result['b_acc']:.4f}\\n\"\n",
    "                    f\"precision: {result['precision']}\\n\"\n",
    "                    f\"recall:    {result['recall']}\\n\"\n",
    "                    f\"f1_score:  {result['f1_score']}\")\n",
    "        plot_confusion_matrix(result[\"c_matrix\"], test_dataset.categories,\n",
    "                              title=f\"ohem {run_id} confusion matrix for {dataset}\",\n",
    "                              filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-cm.png\"))\n",
    "        plot_roc_curves(result[\"roc_curves\"][0],\n",
    "                        result[\"roc_curves\"][1],\n",
    "                        result[\"roc_curves\"][2],\n",
    "                        categories=test_dataset.categories,\n",
    "                        filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-roc_curve.png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型评估\n",
    "为了评估ohem算法对类别倾斜的解决效果，我选择了如下评价指标：\n",
    "- accuracy\n",
    "- balanced accuracy\n",
    "- precision\n",
    "- recall\n",
    "- f1 score\n",
    "- confusion matrix\n",
    "- roc curves(roc-auc)\n",
    "\n",
    "同时我还绘制了训练过程中损失和准确率的变化曲线\n",
    "\n",
    "### 对照组评估\n",
    "对照组即不使用任何应对类别倾斜的方法，按照正常的训练流程训练得到的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER = './run/control'\n",
    "LOGGER = Logger(run_folder=RUN_FOLDER, title='test')\n",
    "LOGGER.info(\"Evaluation for control\")\n",
    "RUN_IDS = ['0001', '0002', '0003']\n",
    "\n",
    "evaluation = Evaluation(device=DEVICE, categories=test_dataset.categories)\n",
    "\n",
    "for run_id in RUN_IDS:\n",
    "    loss_acc = pickle.load(open(os.path.join(RUN_FOLDER, run_id+'obj.pkl'), 'rb'))\n",
    "    plot_losses([loss_acc['train_loss'], loss_acc['train_acc'], loss_acc['valid_loss'], loss_acc['valid_acc']],\n",
    "                title=f\"control {run_id} loss and acc\",\n",
    "                legend=[\"train loss\", \"train acc\", \"valid loss\", \"valid acc\"],\n",
    "                filename=os.path.join(RUN_FOLDER, \"images\", f\"control-{run_id}-loss.png\"))\n",
    "\n",
    "    model = load_model(os.path.join(RUN_FOLDER, \"models\", run_id+\"model.pkl\"),\n",
    "                       device=DEVICE)\n",
    "    for dataset, data_loader in zip(['train', 'valid', 'test'], [train_iter, valid_iter, test_iter]):\n",
    "        LOGGER.info(f\"model {run_id} for {dataset} dataset\")\n",
    "        report = evaluation.get_report(model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"\\n{report}\")\n",
    "        result = evaluation.evaluate(metric=['acc', 'b_acc', 'precision', 'recall', 'f1_score', 'c_matrix', 'roc_curves'],\n",
    "                                     model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"acc:       {result['acc']:.4f}\\n\"\n",
    "                    f\"b_acc:     {result['b_acc']:.4f}\\n\"\n",
    "                    f\"precision: {result['precision']}\\n\"\n",
    "                    f\"recall:    {result['recall']}\\n\"\n",
    "                    f\"f1_score:  {result['f1_score']}\")\n",
    "        plot_confusion_matrix(result[\"c_matrix\"], test_dataset.categories,\n",
    "                              title=f\"control {run_id} confusion matrix for {dataset}\",\n",
    "                              filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-cm.png\"))\n",
    "        plot_roc_curves(result[\"roc_curves\"][0],\n",
    "                        result[\"roc_curves\"][1],\n",
    "                        result[\"roc_curves\"][2],\n",
    "                        categories=test_dataset.categories,\n",
    "                        filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-roc_curve.png\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实验组评估\n",
    "实验组在训练过程中使用了ohem算法，希望能够应对类别倾斜的问题。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN_FOLDER = './run/ohem'\n",
    "LOGGER = Logger(run_folder=RUN_FOLDER, title='test')\n",
    "LOGGER.info(\"Evaluation for ohem\")\n",
    "RUN_IDS = ['0001', '0002', '0003', '0004', '0005', '0006']\n",
    "\n",
    "evaluation = Evaluation(device=DEVICE, categories=test_dataset.categories)\n",
    "\n",
    "for run_id in RUN_IDS:\n",
    "    loss_acc = pickle.load(open(os.path.join(RUN_FOLDER, run_id+'obj.pkl'), 'rb'))\n",
    "    plot_losses([loss_acc['train_loss'], loss_acc['train_acc'], loss_acc['valid_loss'], loss_acc['valid_acc']],\n",
    "                title=f\"ohem {run_id} loss and acc\",\n",
    "                legend=[\"train loss\", \"train acc\", \"valid loss\", \"valid acc\"],\n",
    "                filename=os.path.join(RUN_FOLDER, \"images\", f\"ohem-{run_id}-loss.png\"))\n",
    "\n",
    "    model = load_model(os.path.join(RUN_FOLDER, \"models\", run_id+\"model.pkl\"),\n",
    "                       device=DEVICE)\n",
    "    for dataset, data_loader in zip(['train', 'valid', 'test'], [train_iter, valid_iter, test_iter]):\n",
    "        LOGGER.info(f\"model {run_id} for {dataset} dataset\")\n",
    "        report = evaluation.get_report(model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"\\n{report}\")\n",
    "        result = evaluation.evaluate(metric=['acc', 'b_acc', 'precision', 'recall', 'f1_score', 'c_matrix', 'roc_curves'],\n",
    "                                     model=model, data_loader=data_loader)\n",
    "        LOGGER.info(f\"acc:       {result['acc']:.4f}\\n\"\n",
    "                    f\"b_acc:     {result['b_acc']:.4f}\\n\"\n",
    "                    f\"precision: {result['precision']}\\n\"\n",
    "                    f\"recall:    {result['recall']}\\n\"\n",
    "                    f\"f1_score:  {result['f1_score']}\")\n",
    "        plot_confusion_matrix(result[\"c_matrix\"], test_dataset.categories,\n",
    "                              title=f\"ohem {run_id} confusion matrix for {dataset}\",\n",
    "                              filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-cm.png\"))\n",
    "        plot_roc_curves(result[\"roc_curves\"][0],\n",
    "                        result[\"roc_curves\"][1],\n",
    "                        result[\"roc_curves\"][2],\n",
    "                        categories=test_dataset.categories,\n",
    "                        filename=os.path.join(RUN_FOLDER, \"images\", f\"{run_id+dataset}-roc_curve.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd68f4a13f2237d797c8315ca625e3d0e96d1a82b10adc1960a9ef925778ee3"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('PyTorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}