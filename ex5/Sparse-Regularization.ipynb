{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning With Noisy Labels via Sparse Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "NUM_WORKERS = 0\n",
    "RANDOM_SEED = 123\n",
    "NOISE_RATE = 0.4\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log file\n",
    "from noise.logger import Logger\n",
    "model_id = '1'\n",
    "exp_id = '1-1'\n",
    "model_name = exp_id + '-' + model_id\n",
    "log = Logger(mode='debug', title=exp_id)\n",
    "log.logger.info(\"{}\".format(model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise.data import NoisyISIC2018\n",
    "from torchvision import transforms\n",
    "from torch.utils import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "\n",
    "trans_train = transforms.Compose([\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "trans_test = transforms.Compose([\n",
    "    transforms.CenterCrop((450, 450)),\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "\n",
    "train_data = NoisyISIC2018(ann_file='../../Robust-Skin-Lesion-Diagnosis/Data/2018/Train_GroundTruth.csv',\n",
    "                           img_dir='../../Robust-Skin-Lesion-Diagnosis/Data/2018/ISIC2018_Task3_Training_Input',\n",
    "                           transform=trans_train, noise_type='asymmetric', noise_rate=NOISE_RATE, random_state=RANDOM_SEED)\n",
    "test_data = NoisyISIC2018(ann_file='../../Robust-Skin-Lesion-Diagnosis/Data/2018/Test_GroundTruth.csv',\n",
    "                          img_dir='../../Robust-Skin-Lesion-Diagnosis/Data/2018/ISIC2018_Task3_Training_Input',\n",
    "                          transform=trans_test, noise_type='symmetric', noise_rate=NOISE_RATE, random_state=RANDOM_SEED)\n",
    "valid_data = NoisyISIC2018(ann_file='../../Robust-Skin-Lesion-Diagnosis/Data/2018/ISIC2018_Task3_Validation_GroundTruth.csv',\n",
    "                           img_dir='../../Robust-Skin-Lesion-Diagnosis/Data/2018/ISIC2018_Task3_Validation_Input',\n",
    "                           transform=trans_test, noise_type='symmetric', noise_rate=NOISE_RATE, random_state=RANDOM_SEED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader\n",
    "\n",
    "train_loader = data.DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True, num_workers=NUM_WORKERS)\n",
    "test_loader = data.DataLoader(test_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS)\n",
    "valid_loader = data.DataLoader(valid_data, batch_size=BATCH_SIZE*2, shuffle=False, num_workers=NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.densenet201(pretrained=True)\n",
    "\n",
    "# freeze layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "\n",
    "classifier = nn.Sequential(OrderedDict([\n",
    "    ('fc0', nn.Linear(1920, 256)),\n",
    "    ('norm0', nn.BatchNorm1d(256)),\n",
    "    ('relu0', nn.ReLU(inplace=True)),\n",
    "    ('fc1', nn.Linear(256, 7))\n",
    "]))\n",
    "\n",
    "model.classifier = classifier\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise.train import Trainer\n",
    "from noise.loss import *\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FL + SR\n",
    "criterion = FocalLoss()\n",
    "tau, p, lamb, rho, freq = 0.5, 0.01, 5, 1.002, 1\n",
    "criterion = SR(criterion, tau, p, lamb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## hyper-params\n",
    "init_lr = 1e-3\n",
    "weight_decay = 1e-4\n",
    "max_epoch = 100\n",
    "test_period = 1\n",
    "early_threshold = 40\n",
    "\n",
    "optimizer = optim.AdamW(model.classifier.parameters(), lr=init_lr, betas=(0.9, 0.999), weight_decay=weight_decay)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max_epoch, eta_min=0)\n",
    "\n",
    "trainer = Trainer(device, log, model_name, optimizer, scheduler, checkpoint_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = trainer.fit(model, test_loader, valid_loader, criterion, rho, freq, max_epoch, test_period, early_threshold)\n",
    "print(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from noise.evaluation import evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation(model, test_loader)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "06bb3c3ef4a880548ecfc5dc8501d178eb29b729421bcd01924945e985691c69"
  },
  "kernelspec": {
   "display_name": "Lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
